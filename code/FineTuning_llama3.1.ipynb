{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T07:59:43.852798Z",
     "iopub.status.busy": "2024-09-14T07:59:43.852432Z",
     "iopub.status.idle": "2024-09-14T08:01:48.651718Z",
     "shell.execute_reply": "2024-09-14T08:01:48.650490Z",
     "shell.execute_reply.started": "2024-09-14T07:59:43.852769Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:01:48.654233Z",
     "iopub.status.busy": "2024-09-14T08:01:48.653914Z",
     "iopub.status.idle": "2024-09-14T08:02:06.597901Z",
     "shell.execute_reply": "2024-09-14T08:02:06.597096Z",
     "shell.execute_reply.started": "2024-09-14T08:01:48.654205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 08:01:54.956955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 08:01:54.957072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 08:01:55.150855: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:02:06.599628Z",
     "iopub.status.busy": "2024-09-14T08:02:06.599028Z",
     "iopub.status.idle": "2024-09-14T08:02:10.109024Z",
     "shell.execute_reply": "2024-09-14T08:02:10.108295Z",
     "shell.execute_reply.started": "2024-09-14T08:02:06.599603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n",
      "wandb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melbrahimimeriem\u001b[0m (\u001b[33melbrahimimeriem-university hassan 2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240914_080208-up16ss5d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama31_8B/runs/up16ss5d' target=\"_blank\">icy-fire-4</a></strong> to <a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama31_8B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama31_8B' target=\"_blank\">https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama31_8B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama31_8B/runs/up16ss5d' target=\"_blank\">https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama31_8B/runs/up16ss5d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "login(token = hf_token)\n",
    "\n",
    "wb_token = user_secrets.get_secret(\"wandb\")\n",
    "print(\"wandb\")\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune_Llama31_8B', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")\n",
    "base_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "dataset_name = \"/kaggle/input/dataset-agriculture-pc-k18/dataset_agriculture_pc_18k.xlsx\"\n",
    "new_model = \"llama-31-8b-ft-agri\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:03:11.535382Z",
     "iopub.status.busy": "2024-09-14T08:03:11.534990Z",
     "iopub.status.idle": "2024-09-14T08:05:45.460040Z",
     "shell.execute_reply": "2024-09-14T08:05:45.458923Z",
     "shell.execute_reply.started": "2024-09-14T08:03:11.535354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125ce91682604babbffc817fc9362857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9732da179d7a4b5f86204457c3d71d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a6397eb90f4bfbb12b48d2f14d74fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b39778fa624993a5fada2fc79df8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd585282992340b5b304ec8036d1ba31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba84b8fb2d97471087b5be563e7cb04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88299d5d2d0644f88cf5c68de5a3dd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dee7591f8e9459d90307e2e75a9382c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0547ce8484b4967b31a426b3089b4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb57700f4d54198ada85985166e03ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5089bce2999548bda543ab11dc223a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f2b728b194cc2bb17becd99526ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Context</th>\n",
       "      <th>Prompt_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prunier: Taille de formation</td>\n",
       "      <td>Il faut intervenir sur les pruniers les 7 prem...</td>\n",
       "      <td>Prunier: Taille de formation \\n Il faut interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quels outils utiliser pour la taille d'un prun...</td>\n",
       "      <td>Pour effectuer la taille d'un prunier, il faut...</td>\n",
       "      <td>Quels outils utiliser pour la taille d'un prun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comment procéder à la taille d'un prunier ?</td>\n",
       "      <td>Pour tailler un prunier efficacement, il suffi...</td>\n",
       "      <td>Comment procéder à la taille d'un prunier ? \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semis : comment bien choisir son noyau de pêche ?</td>\n",
       "      <td>Avant de planter un noyau, choisir une pêche d...</td>\n",
       "      <td>Semis : comment bien choisir son noyau de pêch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pourquoi installent-on des pêchers dans les vi...</td>\n",
       "      <td>Les pêches mûrissent au moment des vendanges. ...</td>\n",
       "      <td>Pourquoi installent-on des pêchers dans les vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>Pourquoi choisir une zone large et ensoleillée...</td>\n",
       "      <td>Il est important de choisir un endroit large a...</td>\n",
       "      <td>Pourquoi choisir une zone large et ensoleillée...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>Quel est le sol approprié pour la culture des ...</td>\n",
       "      <td>Si votre sol a été utilisé pour cultiver des f...</td>\n",
       "      <td>Quel est le sol approprié pour la culture des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>Comment protéger les plants de citrouilles des...</td>\n",
       "      <td>Il est important de choisir un endroit pour pl...</td>\n",
       "      <td>Comment protéger les plants de citrouilles des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18207</th>\n",
       "      <td>Quel est le meilleur moment pour planter des c...</td>\n",
       "      <td>Les citrouilles sont très sensibles aux gelées...</td>\n",
       "      <td>Quel est le meilleur moment pour planter des c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>produits de Laâyoune-Sakia el Hamra</td>\n",
       "      <td>Jdari,Camoun Reg,</td>\n",
       "      <td>produits de Laâyoune-Sakia el Hamra  \\n Jdari,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Prompt  \\\n",
       "0                           Prunier: Taille de formation   \n",
       "1      Quels outils utiliser pour la taille d'un prun...   \n",
       "2            Comment procéder à la taille d'un prunier ?   \n",
       "3      Semis : comment bien choisir son noyau de pêche ?   \n",
       "4      Pourquoi installent-on des pêchers dans les vi...   \n",
       "...                                                  ...   \n",
       "18204  Pourquoi choisir une zone large et ensoleillée...   \n",
       "18205  Quel est le sol approprié pour la culture des ...   \n",
       "18206  Comment protéger les plants de citrouilles des...   \n",
       "18207  Quel est le meilleur moment pour planter des c...   \n",
       "18208               produits de Laâyoune-Sakia el Hamra    \n",
       "\n",
       "                                                 Context  \\\n",
       "0      Il faut intervenir sur les pruniers les 7 prem...   \n",
       "1      Pour effectuer la taille d'un prunier, il faut...   \n",
       "2      Pour tailler un prunier efficacement, il suffi...   \n",
       "3      Avant de planter un noyau, choisir une pêche d...   \n",
       "4      Les pêches mûrissent au moment des vendanges. ...   \n",
       "...                                                  ...   \n",
       "18204  Il est important de choisir un endroit large a...   \n",
       "18205  Si votre sol a été utilisé pour cultiver des f...   \n",
       "18206  Il est important de choisir un endroit pour pl...   \n",
       "18207  Les citrouilles sont très sensibles aux gelées...   \n",
       "18208                                  Jdari,Camoun Reg,   \n",
       "\n",
       "                                          Prompt_context  \n",
       "0      Prunier: Taille de formation \\n Il faut interv...  \n",
       "1      Quels outils utiliser pour la taille d'un prun...  \n",
       "2      Comment procéder à la taille d'un prunier ? \\n...  \n",
       "3      Semis : comment bien choisir son noyau de pêch...  \n",
       "4      Pourquoi installent-on des pêchers dans les vi...  \n",
       "...                                                  ...  \n",
       "18204  Pourquoi choisir une zone large et ensoleillée...  \n",
       "18205  Quel est le sol approprié pour la culture des ...  \n",
       "18206  Comment protéger les plants de citrouilles des...  \n",
       "18207  Quel est le meilleur moment pour planter des c...  \n",
       "18208  produits de Laâyoune-Sakia el Hamra  \\n Jdari,...  \n",
       "\n",
       "[18209 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = pd.read_excel(dataset_name)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:06:32.938270Z",
     "iopub.status.busy": "2024-09-14T08:06:32.937671Z",
     "iopub.status.idle": "2024-09-14T08:06:46.051118Z",
     "shell.execute_reply": "2024-09-14T08:06:46.050366Z",
     "shell.execute_reply.started": "2024-09-14T08:06:32.938241Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Définir la fonction format_chat_template avec gestion des erreurs\n",
    "def format_chat_template(row):\n",
    "    try:\n",
    "        # Ajouter un rôle système dédié à l'agriculture au Maroc\n",
    "        row_json = [\n",
    "            {\"role\": \"system\", \"content\": \"Tu es un assistant virtuel dédié à l'agriculture au Maroc. Tu aides les agriculteurs en leur fournissant  des réponses détaillées et adaptées aux conditions locales.\"},\n",
    "            {\"role\": \"user\", \"content\": row[\"Prompt\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"Context\"]}\n",
    "        ]\n",
    "         # Appliquer le modèle de chat en utilisant le tokenizer\n",
    "        row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        print(f\"Row data: {row}\")\n",
    "    return row\n",
    "\n",
    "# Appliquer la fonction au DataFrame nettoyé\n",
    "dataset = dataset.apply(format_chat_template, axis=1)\n",
    "\n",
    "\n",
    "# Diviser le dataset en train et test\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.009, random_state=42)\n",
    "\n",
    "# Convertir le DataFrame pandas en Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:06:46.052821Z",
     "iopub.status.busy": "2024-09-14T08:06:46.052539Z",
     "iopub.status.idle": "2024-09-14T08:06:46.059623Z",
     "shell.execute_reply": "2024-09-14T08:06:46.058574Z",
     "shell.execute_reply.started": "2024-09-14T08:06:46.052797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "Tu es un assistant virtuel dédié à l'agriculture au Maroc. Tu aides les agriculteurs en leur fournissant  des réponses détaillées et adaptées aux conditions locales.<|im_end|>\n",
      "<|im_start|>user\n",
      "La stratification des noyaux d'olive : pas-à-pas<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Choisir des olives très mûres, noires, molles et prêtes à tomber. Gratter le noyau avec du papier de verre ou une lime à ongles. Tremper les graines dans une eau tiède pendant 48h. Mélanger les noyaux dans un pot rempli de sable légèrement humide. Enterrer le pot au pied d'un mur exposé au nord recouvert d'un grillage et des feuilles mortes.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le résultat\n",
    "print(dataset['text'][233])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:06:46.061024Z",
     "iopub.status.busy": "2024-09-14T08:06:46.060738Z",
     "iopub.status.idle": "2024-09-14T13:36:24.395536Z",
     "shell.execute_reply": "2024-09-14T13:36:24.394503Z",
     "shell.execute_reply.started": "2024-09-14T08:06:46.061000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dac43cf19f4bc48b78583236c04ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba7078d284d48aeb8f0426b5bac2acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9022' max='9022' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9022/9022 5:29:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1805</td>\n",
       "      <td>1.689000</td>\n",
       "      <td>1.247787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.167980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5415</td>\n",
       "      <td>1.711300</td>\n",
       "      <td>1.112895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7220</td>\n",
       "      <td>1.005500</td>\n",
       "      <td>1.065341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9022, training_loss=1.1511795892072765, metrics={'train_runtime': 19762.5667, 'train_samples_per_second': 0.913, 'train_steps_per_second': 0.457, 'total_flos': 2.086332032410583e+17, 'train_loss': 1.1511795892072765, 'epoch': 0.999944582986977})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\",\n",
    "    save_steps=0\n",
    ") \n",
    "\n",
    "\n",
    "# Define SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T13:54:38.199361Z",
     "iopub.status.busy": "2024-09-14T13:54:38.198428Z",
     "iopub.status.idle": "2024-09-14T13:57:03.603743Z",
     "shell.execute_reply": "2024-09-14T13:57:03.602832Z",
     "shell.execute_reply.started": "2024-09-14T13:54:38.199325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'heure actuelle est : 13:54:38.204280\n",
      "\n",
      "Les régions les plus adaptées à la culture de la fève au Maroc sont le Gharb, le Loukkos, le Souss-Massa et le Haouz. Ces régions bénéficient d'un climat doux et d'un sol riche en nutriments, ce qui favorise la croissance et le rendement des cultures. La fève est également cultivée dans d'autres régions du Maroc, mais ces régions présentent des conditions climatiques et édaphiques plus défavorables. Il est important de choisir les régions appropriées en fonction des caractéristiques du sol et des conditions météorologiques pour assurer une croissance optimale et un rendement élevé.  \n",
      "L'heure actuelle est : 13:57:03.600297\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Obtenir l'heure actuelle\n",
    "heure_actuelle = datetime.now().time()\n",
    "\n",
    "# Afficher l'heure actuelle\n",
    "print(\"L'heure actuelle est :\", heure_actuelle)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"quelles régions sont appropriées pour la culture des fèves au maroc\"\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=550,\n",
    "    \n",
    "    temperature=0.7,\n",
    "    top_p=0.9, \n",
    "    no_repeat_ngram_size=3,  # Avoid repeating n-grams\n",
    "    num_beams=5,  # Use beam search for completeness\n",
    "    early_stopping=True # Ajouter une pénalité de répétition\n",
    ")\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "a=text.split(\"assistant\")[1]\n",
    "print(a.split(\"Source :\")[0])\n",
    "heure_actuelle = datetime.now().time()\n",
    "print(\"L'heure actuelle est :\", heure_actuelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T13:36:36.212845Z",
     "iopub.status.busy": "2024-09-14T13:36:36.211930Z",
     "iopub.status.idle": "2024-09-14T13:37:51.286376Z",
     "shell.execute_reply": "2024-09-14T13:37:51.285491Z",
     "shell.execute_reply.started": "2024-09-14T13:36:36.212810Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1854d75d12b04a03b063597f49884472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcd9ac7f798418e9cda9c1422706a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MeelUnv/llama3.1_agri/commit/b560529ab4dfc7a1e792152bb914489e4dac2e09', commit_message='Upload model', commit_description='', oid='b560529ab4dfc7a1e792152bb914489e4dac2e09', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"llama3.1_agri\")\n",
    "tokenizer.save_pretrained(\"llama3.1_agri\")\n",
    "#trainer.model.config.push_to_hub(\"laila1234/fine-tuned-llama3-300l-without config\")\n",
    "tokenizer.push_to_hub(\"MeelUnv/llama3.1_agri\")\n",
    "model.push_to_hub(\"MeelUnv/llama3.1_agri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T13:39:41.561914Z",
     "iopub.status.busy": "2024-09-14T13:39:41.561551Z",
     "iopub.status.idle": "2024-09-14T13:39:42.170610Z",
     "shell.execute_reply": "2024-09-14T13:39:42.169725Z",
     "shell.execute_reply.started": "2024-09-14T13:39:41.561886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MeelUnv/llama3.1_agri/commit/6aaf5adf5301311dd92526819189cede994bbe79', commit_message='Upload config', commit_description='', oid='6aaf5adf5301311dd92526819189cede994bbe79', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = trainer.model.config\n",
    "config.push_to_hub(\"MeelUnv/llama3.1_agri\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5566401,
     "sourceId": 9206188,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5566415,
     "sourceId": 9206207,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
