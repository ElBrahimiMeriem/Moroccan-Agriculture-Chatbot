{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:55:26.448460Z",
     "iopub.status.busy": "2024-09-16T09:55:26.448150Z",
     "iopub.status.idle": "2024-09-16T09:57:29.092787Z",
     "shell.execute_reply": "2024-09-16T09:57:29.091708Z",
     "shell.execute_reply.started": "2024-09-16T09:55:26.448430Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:57:29.095679Z",
     "iopub.status.busy": "2024-09-16T09:57:29.094944Z",
     "iopub.status.idle": "2024-09-16T09:57:47.554294Z",
     "shell.execute_reply": "2024-09-16T09:57:47.553526Z",
     "shell.execute_reply.started": "2024-09-16T09:57:29.095643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 09:57:36.700571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-16 09:57:36.700666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-16 09:57:36.860350: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:04.204741Z",
     "iopub.status.busy": "2024-09-16T09:59:04.204013Z",
     "iopub.status.idle": "2024-09-16T09:59:05.344161Z",
     "shell.execute_reply": "2024-09-16T09:59:05.343214Z",
     "shell.execute_reply.started": "2024-09-16T09:59:04.204711Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:12.373944Z",
     "iopub.status.busy": "2024-09-16T09:59:12.372608Z",
     "iopub.status.idle": "2024-09-16T09:59:16.314589Z",
     "shell.execute_reply": "2024-09-16T09:59:16.313738Z",
     "shell.execute_reply.started": "2024-09-16T09:59:12.373908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n",
      "wandb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melbrahimimeriem\u001b[0m (\u001b[33melbrahimimeriem-university hassan 2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240916_095914-2rbfi7ey</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama2_7B/runs/2rbfi7ey' target=\"_blank\">rosy-lake-3</a></strong> to <a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama2_7B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama2_7B' target=\"_blank\">https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama2_7B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama2_7B/runs/2rbfi7ey' target=\"_blank\">https://wandb.ai/elbrahimimeriem-university%20hassan%202/Fine-tune_Llama2_7B/runs/2rbfi7ey</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "login(token = hf_token)\n",
    "\n",
    "wb_token = user_secrets.get_secret(\"wandb\")\n",
    "print(\"wandb\")\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune_Llama2_7B', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:25.122424Z",
     "iopub.status.busy": "2024-09-16T09:59:25.122072Z",
     "iopub.status.idle": "2024-09-16T09:59:25.127918Z",
     "shell.execute_reply": "2024-09-16T09:59:25.127053Z",
     "shell.execute_reply.started": "2024-09-16T09:59:25.122395Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "dataset_name = \"/kaggle/input/dataset-agriculture-pc-k18/dataset_agriculture_pc_18k.xlsx\"\n",
    "new_model = \"llama-2-7b-ft-agri\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T09:59:28.875637Z",
     "iopub.status.busy": "2024-09-16T09:59:28.875285Z",
     "iopub.status.idle": "2024-09-16T10:00:37.982339Z",
     "shell.execute_reply": "2024-09-16T10:00:37.981183Z",
     "shell.execute_reply.started": "2024-09-16T09:59:28.875608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5253efce2249b88f173f4d057b52c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065130b746bd417884949305e6f588ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c77bf2188e40479ca13770248cde38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8542646c984e68a3196e6ac89a5f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaa707f212f42c892f07339d66e4578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c707623cac491d9a653d02e6d7d1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d9d194ed1b4fec9f8aacb61e780940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:00:52.470930Z",
     "iopub.status.busy": "2024-09-16T10:00:52.470544Z",
     "iopub.status.idle": "2024-09-16T10:00:53.948546Z",
     "shell.execute_reply": "2024-09-16T10:00:53.947562Z",
     "shell.execute_reply.started": "2024-09-16T10:00:52.470899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8887a0dc993b44ae8a073d0ba3d91783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2814c098c97a479cbad2b4f5f1fce1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20802893d73496583d14cad17a6fad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c1434ca7344afd881ca1cddcaf3c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff9ea2ce7ba4a22a261b0a02d8358a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:00:56.835883Z",
     "iopub.status.busy": "2024-09-16T10:00:56.835521Z",
     "iopub.status.idle": "2024-09-16T10:00:57.713663Z",
     "shell.execute_reply": "2024-09-16T10:00:57.712665Z",
     "shell.execute_reply.started": "2024-09-16T10:00:56.835851Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Context</th>\n",
       "      <th>Prompt_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prunier: Taille de formation</td>\n",
       "      <td>Il faut intervenir sur les pruniers les 7 prem...</td>\n",
       "      <td>Prunier: Taille de formation \\n Il faut interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quels outils utiliser pour la taille d'un prun...</td>\n",
       "      <td>Pour effectuer la taille d'un prunier, il faut...</td>\n",
       "      <td>Quels outils utiliser pour la taille d'un prun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comment procéder à la taille d'un prunier ?</td>\n",
       "      <td>Pour tailler un prunier efficacement, il suffi...</td>\n",
       "      <td>Comment procéder à la taille d'un prunier ? \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semis : comment bien choisir son noyau de pêche ?</td>\n",
       "      <td>Avant de planter un noyau, choisir une pêche d...</td>\n",
       "      <td>Semis : comment bien choisir son noyau de pêch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pourquoi installent-on des pêchers dans les vi...</td>\n",
       "      <td>Les pêches mûrissent au moment des vendanges. ...</td>\n",
       "      <td>Pourquoi installent-on des pêchers dans les vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>Pourquoi choisir une zone large et ensoleillée...</td>\n",
       "      <td>Il est important de choisir un endroit large a...</td>\n",
       "      <td>Pourquoi choisir une zone large et ensoleillée...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>Quel est le sol approprié pour la culture des ...</td>\n",
       "      <td>Si votre sol a été utilisé pour cultiver des f...</td>\n",
       "      <td>Quel est le sol approprié pour la culture des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18206</th>\n",
       "      <td>Comment protéger les plants de citrouilles des...</td>\n",
       "      <td>Il est important de choisir un endroit pour pl...</td>\n",
       "      <td>Comment protéger les plants de citrouilles des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18207</th>\n",
       "      <td>Quel est le meilleur moment pour planter des c...</td>\n",
       "      <td>Les citrouilles sont très sensibles aux gelées...</td>\n",
       "      <td>Quel est le meilleur moment pour planter des c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>produits de Laâyoune-Sakia el Hamra</td>\n",
       "      <td>Jdari,Camoun Reg,</td>\n",
       "      <td>produits de Laâyoune-Sakia el Hamra  \\n Jdari,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Prompt  \\\n",
       "0                           Prunier: Taille de formation   \n",
       "1      Quels outils utiliser pour la taille d'un prun...   \n",
       "2            Comment procéder à la taille d'un prunier ?   \n",
       "3      Semis : comment bien choisir son noyau de pêche ?   \n",
       "4      Pourquoi installent-on des pêchers dans les vi...   \n",
       "...                                                  ...   \n",
       "18204  Pourquoi choisir une zone large et ensoleillée...   \n",
       "18205  Quel est le sol approprié pour la culture des ...   \n",
       "18206  Comment protéger les plants de citrouilles des...   \n",
       "18207  Quel est le meilleur moment pour planter des c...   \n",
       "18208               produits de Laâyoune-Sakia el Hamra    \n",
       "\n",
       "                                                 Context  \\\n",
       "0      Il faut intervenir sur les pruniers les 7 prem...   \n",
       "1      Pour effectuer la taille d'un prunier, il faut...   \n",
       "2      Pour tailler un prunier efficacement, il suffi...   \n",
       "3      Avant de planter un noyau, choisir une pêche d...   \n",
       "4      Les pêches mûrissent au moment des vendanges. ...   \n",
       "...                                                  ...   \n",
       "18204  Il est important de choisir un endroit large a...   \n",
       "18205  Si votre sol a été utilisé pour cultiver des f...   \n",
       "18206  Il est important de choisir un endroit pour pl...   \n",
       "18207  Les citrouilles sont très sensibles aux gelées...   \n",
       "18208                                  Jdari,Camoun Reg,   \n",
       "\n",
       "                                          Prompt_context  \n",
       "0      Prunier: Taille de formation \\n Il faut interv...  \n",
       "1      Quels outils utiliser pour la taille d'un prun...  \n",
       "2      Comment procéder à la taille d'un prunier ? \\n...  \n",
       "3      Semis : comment bien choisir son noyau de pêch...  \n",
       "4      Pourquoi installent-on des pêchers dans les vi...  \n",
       "...                                                  ...  \n",
       "18204  Pourquoi choisir une zone large et ensoleillée...  \n",
       "18205  Quel est le sol approprié pour la culture des ...  \n",
       "18206  Comment protéger les plants de citrouilles des...  \n",
       "18207  Quel est le meilleur moment pour planter des c...  \n",
       "18208  produits de Laâyoune-Sakia el Hamra  \\n Jdari,...  \n",
       "\n",
       "[18209 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = pd.read_excel(dataset_name)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:02:17.675265Z",
     "iopub.status.busy": "2024-09-16T10:02:17.674902Z",
     "iopub.status.idle": "2024-09-16T10:02:19.377007Z",
     "shell.execute_reply": "2024-09-16T10:02:19.376070Z",
     "shell.execute_reply.started": "2024-09-16T10:02:17.675238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tu es un assistant virtuel dédié à l'agriculture au Maroc. Tu aides les agriculteurs en leur fournissant  des réponses détaillées et adaptées aux conditions locales.\n",
      "    <s>[PROMPT] La stratification des noyaux d'olive : pas-à-pas [/PROMPT] Choisir des olives très mûres, noires, molles et prêtes à tomber. Gratter le noyau avec du papier de verre ou une lime à ongles. Tremper les graines dans une eau tiède pendant 48h. Mélanger les noyaux dans un pot rempli de sable légèrement humide. Enterrer le pot au pied d'un mur exposé au nord recouvert d'un grillage et des feuilles mortes. </s>\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "def transform_dataset(dataset):\n",
    "    transformed_data = []\n",
    "    system_message =\"\"\"\n",
    "    Tu es un assistant virtuel dédié à l'agriculture au Maroc. Tu aides les agriculteurs en leur fournissant  des réponses détaillées et adaptées aux conditions locales.\n",
    "    \"\"\" \n",
    "    for index, example in dataset.iterrows():\n",
    "        prompt = str(example['Prompt']).strip() if pd.notna(example['Prompt']) else \"\"\n",
    "        response = str(example['Context']).strip() if pd.notna(example['Context']) else \"\"\n",
    "\n",
    "        # Apply the new template (assuming [PROMPT] and [RESPONSE] placeholders)\n",
    "        transformed_example = f'{system_message}<s>[PROMPT] {prompt} [/PROMPT] {response} </s>'\n",
    "\n",
    "        transformed_data.append(transformed_example)\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "# Appliquer la fonction au DataFrame nettoyé\n",
    "transformed_data = transform_dataset(dataset)\n",
    "\n",
    "# Créer un DataFrame pandas à partir des données transformées\n",
    "df_transformed = pd.DataFrame({'text': transformed_data})\n",
    "\n",
    "# Utiliser Dataset.from_pandas pour convertir en Dataset Hugging Face\n",
    "dataset = Dataset.from_pandas(df_transformed)\n",
    "\n",
    "# Vérifier le résultat\n",
    "print(dataset['text'][233])\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Diviser les données en ensemble d'entraînement et de test\n",
    "train_df, test_df = train_test_split(df_transformed, test_size=0.009, random_state=42)\n",
    "\n",
    "# Convertir les DataFrames pandas en Dataset Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:02:27.113433Z",
     "iopub.status.busy": "2024-09-16T10:02:27.112600Z",
     "iopub.status.idle": "2024-09-16T10:02:33.953616Z",
     "shell.execute_reply": "2024-09-16T10:02:33.952726Z",
     "shell.execute_reply.started": "2024-09-16T10:02:27.113401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8f66e003ec424b9fd85c6882d55db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e664f60e344b3da91c331b9bb0ddae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:407: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\",\n",
    "    save_steps=0\n",
    ") \n",
    "\n",
    "\n",
    "# Define SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:02:52.772895Z",
     "iopub.status.busy": "2024-09-16T10:02:52.772237Z",
     "iopub.status.idle": "2024-09-16T14:53:53.016362Z",
     "shell.execute_reply": "2024-09-16T14:53:53.015284Z",
     "shell.execute_reply.started": "2024-09-16T10:02:52.772863Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9022' max='9022' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9022/9022 4:50:49, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1805</td>\n",
       "      <td>1.344500</td>\n",
       "      <td>1.170764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>1.213500</td>\n",
       "      <td>1.096950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5415</td>\n",
       "      <td>1.307800</td>\n",
       "      <td>1.042395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7220</td>\n",
       "      <td>1.026300</td>\n",
       "      <td>1.001693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9022, training_loss=1.0628780049191984, metrics={'train_runtime': 17452.8801, 'train_samples_per_second': 1.034, 'train_steps_per_second': 0.517, 'total_flos': 2.0129608926353818e+17, 'train_loss': 1.0628780049191984, 'epoch': 0.999944582986977})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T15:11:55.591839Z",
     "iopub.status.busy": "2024-09-16T15:11:55.591473Z",
     "iopub.status.idle": "2024-09-16T15:12:25.429666Z",
     "shell.execute_reply": "2024-09-16T15:12:25.428772Z",
     "shell.execute_reply.started": "2024-09-16T15:11:55.591809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30c4d6a556a4866991c1d1ab44485e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221fede079b8482da3eb9bbe58cfea64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3046969aba4005b55e24ebfcf7364e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/684M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MeelUnv/llama2_agri/commit/c9b2bf6ba182d98e3163f29bbc5e175b5fdf639b', commit_message='Upload config', commit_description='', oid='c9b2bf6ba182d98e3163f29bbc5e175b5fdf639b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"llama2_agri\")\n",
    "tokenizer.save_pretrained(\"llama2_agri\")\n",
    "#trainer.model.config.push_to_hub(\"laila1234/fine-tuned-llama3-300l-without config\")\n",
    "tokenizer.push_to_hub(\"MeelUnv/llama2_agri\")\n",
    "model.push_to_hub(\"MeelUnv/llama2_agri\")\n",
    "config = trainer.model.config\n",
    "config.push_to_hub(\"MeelUnv/llama2_agri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T15:31:08.594756Z",
     "iopub.status.busy": "2024-09-16T15:31:08.593958Z",
     "iopub.status.idle": "2024-09-16T15:33:04.140633Z",
     "shell.execute_reply": "2024-09-16T15:33:04.139639Z",
     "shell.execute_reply.started": "2024-09-16T15:31:08.594723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'heure actuelle est : 15:31:08.598977\n",
      " Les principales régions de culture de la fève au Maroc sont le Gharb, le Souss-Massa, le Haouz, le Saïs et le Doukkala.[1]\n",
      "L'heure actuelle est : 15:33:04.136822\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Obtenir l'heure actuelle\n",
    "heure_actuelle = datetime.now().time()\n",
    "\n",
    "# Afficher l'heure actuelle\n",
    "print(\"L'heure actuelle est :\", heure_actuelle)\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,\n",
    "                max_length=550,\n",
    "    \n",
    "    temperature=0.7,\n",
    "    top_p=0.9, \n",
    "    no_repeat_ngram_size=3,  # Avoid repeating n-grams\n",
    "    num_beams=5,  # Use beam search for completeness\n",
    "    early_stopping=True # Ajouter une pénalité de répétition  \n",
    "    \n",
    ")\n",
    "\n",
    "# Disable logging to prevent excessive output\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "q=\"quelles régions sont appropriées pour la culture des fèves au maroc\"\n",
    "text=pipe(f\"<s>[INST] {q} [/INST]\")\n",
    "a=text[0]['generated_text']\n",
    "a=a.split(\"[/INST]\")[1].split(\"[/INST:\")[0]\n",
    "print(a)\n",
    "heure_actuelle = datetime.now().time()\n",
    "print(\"L'heure actuelle est :\", heure_actuelle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5566401,
     "sourceId": 9206188,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5566415,
     "sourceId": 9206207,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
